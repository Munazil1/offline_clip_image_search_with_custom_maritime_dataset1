# offline_clip_image_search_with_custom_maritime_dataset
A fully offline semantic image search tool using OpenAI's CLIP ViT-L/14 model and a custom maritime dataset. Supports both natural language and reverse image queries, with a feedback loop and Flask-based desktop UI. Designed for secure, air-gapped environments like defense and surveillance systems.

clip_image_search/
â”œâ”€â”€ app.py # Main Flask/Streamlit app
â”œâ”€â”€ utils.py # Utility functions for embedding and search
â”œâ”€â”€ preprocess_features.py # Preprocessing & embedding images
â”œâ”€â”€ templates/index.html # Web UI (if Flask used)
â”œâ”€â”€ caption_image_map.json # Optional: image to caption mapping
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ .gitignore # Files to exclude from Git
â””â”€â”€ README.md # Project documentation

bash
Copy
Edit

## ðŸš€ How to Run

1. **Clone the repository**

git clone https://github.com/Munazil1/offline_clip_image_search_with_custom_maritime_dataset1.git
cd offline_clip_image_search_with_custom_maritime_dataset1
Install dependencies


pip install -r requirements.txt
Run the app

python app.py
Or use Streamlit/Gradio if configured.

ðŸ§  How It Works
Images and captions are embedded using CLIP.

All embeddings are stored locally (.npy, .json, etc.).

When a query is entered, itâ€™s embedded and compared to image vectors using cosine similarity.

The top matches are returned and displayed.

ðŸ“¦ Dependencies
openai-clip or transformers

torch

flask, streamlit, or gradio

numpy, PIL, scikit-learn, faiss (optional)

Install them using:

pip install -r requirements.txt
ðŸ“¸ Sample Use Case
Search for:

"Red cargo ship in storm"

And get back:

cargo_red_002.jpg

stormy_ocean_tanker.jpg

ðŸ“„ License
This project is open-source and free to use under the MIT License.
